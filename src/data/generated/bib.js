const generatedBibEntries = {
    " ": {
        "abstract": "Image segmentation is a fundamental task in the field of imaging and vision. Supervised deep learning for segmentation has achieved unparalleled success when sufficient training data with annotated labels are available. However, annotation is known to be expensive to obtain, especially for histopathology images where the target regions are usually with high morphology variations and irregular shapes. Thus, weakly supervised learning with sparse annotations of points is promising to reduce the annotation workload. In this work, we propose a contrast-based variational model to generate segmentation results, which serve as reliable complementary supervision to train a deep segmentation model for histopathology images. The proposed method considers the common characteristics of target regions in histopathology images and can be trained in an end-to-end manner. It can generate more regionally consistent and smoother boundary segmentation, and is more robust to unlabeled \u2018novel\u2019 regions. Experiments on two different histology datasets demonstrate its effectiveness and efficiency in comparison to previous models. Code is available at: https://github.com/hrzhang1123/CVM\\_WS\\_Segmentation.",
        "author": "Zhang, Hongrun and Burrows, Liam and Meng, Yanda and Sculthorpe, Declan and Mukherjee, Abhik and Coupland, Sarah E. and Chen, Ke and Zheng, Yalin",
        "conference": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "doi": "10.1109/cvpr52729.2023.01500",
        "isbn": "979-8-3503-0130-4",
        "keyword": "Image segmentation , Histopathology , Annotations , Shape , Supervised learning , Training data , Morphology , Medical and biological vision , cell microscopy",
        "pages": "15630-15640",
        "publicationstatus": "Published",
        "publisher": "Institute of Electrical and Electronics Engineers",
        "title": "Weakly Supervised Segmentation with Point Annotations for Histopathology Images via Contrast-Based Variational Model",
        "type": "misc",
        "url": "https://nottingham-repository.worktribe.com/output/25057462",
        "volume": "2023-June",
        "year": "2023"
    },
    "10.1007/978-3-031-72117-5_52": {
        "abstract": "Medical image classification is an important task in many different medical applications. The past years have witnessed the success of Deep Neural Networks (DNNs) in medical image classification. However, traditional softmax outputs produced by DNNs fail to estimate uncertainty in medical image predictions. Contrasting with conventional uncertainty estimation approaches, conformal prediction (CP) stands out as a model-agnostic and distribution-free methodology that constructs statistically rigorous uncertainty sets for model predictions. However, existing exact full conformal methods involve retraining the underlying DNN model for each test instance with each possible label, demanding substantial computational resources. Additionally, existing works fail to uncover the root causes of medical prediction uncertainty, making it difficult for doctors to interpret the estimated uncertainties associated with medical diagnoses. To address these challenges, in this paper, we first propose an efficient approximate full CP method, which involves tracking the gradient updates contributed by these samples during training. Subsequently, we design an interpretation method that uses these updates to identify the top-k most influential training samples that significantly impact models' uncertainties. Extensive experiments on real-world medical image datasets are conducted to verify the effectiveness of the proposed methods.",
        "address": "Cham",
        "author": "Chen, Aobo and Li, Yangyi and Qian, Wei and Morse, Kathryn and Miao, Chenglin and Huai, Mengdi",
        "booktitle": "Medical Image Computing and Computer Assisted Intervention -- MICCAI 2024",
        "doi": "https://doi.org/10.1007/978-3-031-72117-5_52",
        "editor": "Linguraru, Marius George and Dou, Qi and Feragen, Aasa and Giannarou, Stamatia and Glocker, Ben and Lekadir, Karim and Schnabel, Julia A.",
        "isbn": "978-3-031-72117-5",
        "pages": "557--567",
        "publisher": "Springer Nature Switzerland",
        "title": "Modeling and\u00a0Understanding Uncertainty in\u00a0Medical Image Classification",
        "type": "InProceedings",
        "year": "2024"
    },
    "10.1007/978-3-031-72120-5_42": {
        "abstract": "In recent years, transformer-based image classification methods have demonstrated remarkable effectiveness across various image classification tasks. However, their application to medical images presents challenges, especially in the feature extraction capability of the network. Additionally, these models often struggle with the efficient propagation of essential information throughout the network, hindering their performance in medical imaging tasks. To overcome these challenges, we introduce a novel framework comprising Local-Global Transformer module and Spatial Attention Fusion module, collectively referred to as Med-Former. These modules are specifically designed to enhance the feature extraction capability at both local and global levels and improve the propagation of vital information within the network. To evaluate the efficacy of our proposed Med-Former framework, we conducted experiments on three publicly available medical image datasets: NIH Chest X-ray14, DermaMNIST, and BloodMNIST. Our results demonstrate that Med-Former outperforms state-of-the-art approaches underscoring its superior generalization capability and effectiveness in medical image classification.",
        "address": "Cham",
        "author": "Chowdary, G. Jignesh and Yin, Zhaozheng",
        "booktitle": "Medical Image Computing and Computer Assisted Intervention -- MICCAI 2024",
        "doi": "https://doi.org/10.1007/978-3-031-72120-5_42 Keywords: {Medical Image Classification \u00b7 Transformers \u00b7 Computer Aided Diagnosis \u00b7 Local-global Feature Extraction \u00b7 Spatial Attention Fusion",
        "editor": "Linguraru, Marius George and Dou, Qi and Feragen, Aasa and Giannarou, Stamatia and Glocker, Ben and Lekadir, Karim and Schnabel, Julia A.",
        "isbn": "978-3-031-72120-5",
        "pages": "448--457",
        "publisher": "Springer Nature Switzerland",
        "title": "Med-Former: A Transformer Based Architecture for\u00a0Medical Image Classification",
        "type": "InProceedings",
        "year": "2024"
    },
    "10651469": {
        "author": "Huang, Xinlei and Jiang, Ning and Tang, Jialiang",
        "booktitle": "2024 International Joint Conference on Neural Networks (IJCNN)",
        "doi": "10.1109/IJCNN60899.2024.10651469",
        "keywords": "Knowledge engineering;Degradation;Accuracy;Design automation;Interference;Prediction algorithms;Skin;skin lesions classification;brain tumor classification;model compression;knowledge distillation",
        "number": "",
        "pages": "1-8",
        "title": "ClearKD: Clear Knowledge Distillation for Medical Image Classification",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2024"
    },
    "9412946": {
        "abstract": "Coronavirus (Covid-19) is spreading fast, infecting people through contact in various forms including droplets from sneezing and coughing. Therefore, the detection of infected subjects in an early, quick and cheap manner is urgent. Currently available tests are scarce and limited to people in danger of serious illness. The application of deep learning to chest X-ray images for Covid-19 detection is an attractive approach. However, this technology usually relies on the availability of large labelled datasets, a requirement hard to meet in the context of a virus outbreak. To overcome this challenge, a semi-supervised deep learning model using both labelled and unlabelled data is proposed. We developed and tested a semi-supervised deep learning framework based on the Mix Match architecture to classify chest X-rays into Covid-19, pneumonia and healthy cases. The presented approach was calibrated using two publicly available datasets. The results show an accuracy increase of around 15\\% under low labelled / unlabelled data ratio. This indicates that our semi-supervised framework can help improve performance levels towards Covid-19 detection when the amount of high-quality labelled data is scarce. Also, we introduce a semi-supervised deep learning boost coefficient which is meant to ease the scalability of our approach and performance comparison.",
        "author": "Calderon-Ramirez, Saul and Giri, Raghvendra and Yang, Shengxiang and Moemeni, Armaghan and Uma\u00f1a, Mario and Elizondo, David and Torrents-Barrena, Jordina and Molina-Cabello, Miguel A.",
        "booktitle": "2020 25th International Conference on Pattern Recognition (ICPR)",
        "conference": " 2020 25th International Conference on Pattern Recognition (ICPR 2020)",
        "doi": "10.1109/ICPR48806.2021.9412946",
        "keywords": "Deep learning;COVID-19;Training;Solid modeling;Scalability;X-rays;Semisupervised learning;Semi-supervised Deep Learning;Mix Match;Chest X-Ray;Covid-19;Computer Aided Diagnosis",
        "number": "",
        "pages": "5294-5301",
        "title": "Dealing with Scarce Labelled Data: Semi-supervised Deep Learning with Mix Match for Covid-19 Detection Using Chest X-ray Images",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2021"
    },
    "9533719": {
        "author": "Calder\u00f3n-Ram\u00edrez, Sa\u00fal and Murillo-Hern\u00e1ndez, Diego and Rojas-Salazar, Kevin and Calvo-Valverd, Luis-Alexander and Yang, Shengxiang and Moemeni, Armaghan and Elizondo, David and L\u00f3pez-Rubio, Ezequiel and Molina-Cabello, Miguel A.",
        "booktitle": "2021 International Joint Conference on Neural Networks (IJCNN)",
        "doi": "10.1109/IJCNN52387.2021.9533719",
        "keywords": "Deep learning;Training;Uncertainty;Computational modeling;Neural networks;Estimation;Semisupervised learning;Uncertainty Estimation;Breast Cancer;Mammogram;Semi-Supervised Deep Learning;MixMatch",
        "number": "",
        "pages": "1-8",
        "title": "Improving Uncertainty Estimations for Mammogram Classification using Semi-Supervised Learning",
        "type": "INPROCEEDINGS",
        "volume": "",
        "year": "2021"
    },
    "AZAD2024103000": {
        "abstract": "The remarkable performance of the Transformer architecture in natural language processing has recently also triggered broad interest in Computer Vision. Among other merits, Transformers are witnessed as capable of learning long-range dependencies and spatial correlations, which is a clear advantage over convolutional neural networks (CNNs), which have been the de facto standard in Computer Vision problems so far. Thus, Transformers have become an integral part of modern medical image analysis. In this review, we provide an encyclopedic review of the applications of Transformers in medical imaging. Specifically, we present a systematic and thorough review of relevant recent Transformer literature for different medical image analysis tasks, including classification, segmentation, detection, registration, synthesis, and clinical report generation. For each of these applications, we investigate the novelty, strengths and weaknesses of the different proposed strategies and develop taxonomies highlighting key properties and contributions. Further, if applicable, we outline current benchmarks on different datasets. Finally, we summarize key challenges and discuss different future research directions. In addition, we have provided cited papers with their corresponding implementations in https://github.com/mindflow-institue/Awesome-Transformer.",
        "author": "Reza Azad and Amirhossein Kazerouni and Moein Heidari and Ehsan Khodapanah Aghdam and Amirali Molaei and Yiwei Jia and Abin Jose and Rijo Roy and Dorit Merhof",
        "doi": "https://doi.org/10.1016/j.media.2023.103000",
        "issn": "1361-8415",
        "journal": "Medical Image Analysis",
        "keywords": "Transformers, Medical image analysis, Vision transformers, Deep neural networks",
        "pages": "103000",
        "title": "Advances in medical image analysis with vision Transformers: A comprehensive review",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S1361841523002608",
        "volume": "91",
        "year": "2024"
    },
    "PACHETTI2024102949": {
        "abstract": "The lack of annotated medical images limits the performance of deep learning models, which usually need large-scale labelled datasets. Few-shot learning techniques can reduce data scarcity issues and enhance medical image analysis speed and robustness. This systematic review gives a comprehensive overview of few-shot learning methods for medical image analysis, aiming to establish a standard methodological pipeline for future research reference. With a particular emphasis on the role of meta-learning, we analysed 80 relevant articles published from 2018 to 2023, conducting a risk of bias assessment and extracting relevant information, especially regarding the employed learning techniques. From this, we delineated a comprehensive methodological pipeline shared among all studies. In addition, we performed a statistical analysis of the studies\u2019 results concerning the clinical task and the meta-learning method employed while also presenting supplemental information such as imaging modalities and model robustness evaluation techniques. We discussed the findings of our analysis, providing a deep insight into the limitations of the state-of-the-art methods and the most promising approaches. Drawing on our investigation, we yielded recommendations on potential future research directions aiming to bridge the gap between research and clinical practice.",
        "author": "Eva Pachetti and Sara Colantonio",
        "doi": "https://doi.org/10.1016/j.artmed.2024.102949",
        "issn": "0933-3657",
        "journal": "Artificial Intelligence in Medicine",
        "keywords": "Few-shot learning, Medical imaging, Systematic review",
        "pages": "102949",
        "title": "A systematic review of few-shot learning in medical imaging",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/pii/S093336572400191X",
        "volume": "156",
        "year": "2024"
    },
    "Sha_Confidence_MICCAI2024": {
        "author": " Sharma, Saurabh and Kumar, Atul and Chandra, Joydeep",
        "booktitle": "proceedings of Medical Image Computing and Computer Assisted Intervention -- MICCAI 2024",
        "doi": "https://doi.org/10.1007/978-3-031-72117-5_13",
        "image": "data/papers_img/paper1.png",
        "month": "October",
        "page": "133 -- 142",
        "publisher": "Springer Nature Switzerland",
        "title": " { Confidence Matters: Enhancing Medical Image Classification Through Uncertainty-Driven Contrastive Self-Distillation } ",
        "type": "InProceedings",
        "volume": "LNCS 15010",
        "year": "2024"
    },
    "Xing2021CategoricalRC": {
        "author": "Xiaohan Xing and Yuenan Hou and Han Li and Yixuan Yuan and Hongsheng Li and Max Q.\u2010H. Meng",
        "booktitle": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
        "doi": "https://doi.org/10.48550/arXiv.2107.03225",
        "title": "Categorical Relation-Preserving Contrastive Knowledge Distillation for Medical Image Classification",
        "type": "inproceedings",
        "url": "https://api.semanticscholar.org/CorpusID:235755366",
        "year": "2021"
    }
};